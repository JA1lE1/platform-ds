# Copyright (c) Jupyter Development Team.
# Distributed under the terms of the Modified BSD License.

# JupyterHub docker-compose configuration file
version: '3.1'

services:
  jupyter:
    image: jupyter/pyspark-notebook
    container_name: jupyter
    hostname: jupyter
    ports:
      - "10000:8888"
    environment:
      - JUPYTER_ENABLE_LAB=yes 

  spark-master:
    build:
      context: ./spark-master
      dockerfile: Dockerfile
      args:
        http_proxy:
        https_proxy:
        ftp_proxy:
    image: spark-master:2.4.4
    container_name: spark-master
    hostname: spark-master
    ports:
      - "8585:8080"
      - "7077:7077"
    volumes:
      - /mnt/spark-apps:/opt/spark-apps
      - /mnt/spark-data:/opt/spark-data
            
  spark-worker-1:
    build:
      context: ./spark-worker
      dockerfile: Dockerfile
      args:
        http_proxy:
        https_proxy:
        ftp_proxy:
    image: spark-worker:2.4.4
    container_name: spark-worker-1
    hostname: spark-worker-1
    depends_on:
      - spark-master
    ports:
      - "8081:8081"
    volumes:
       - /mnt/spark-apps:/opt/spark-apps
       - /mnt/spark-data:/opt/spark-data

  spark-worker-2:
    depends_on:
      - spark-worker-1
    image: spark-worker:2.4.4
    container_name: spark-worker-2
    hostname: spark-worker-2
    depends_on:
      - spark-master
    ports:
      - "8082:8081"
    volumes:
       - /mnt/spark-apps:/opt/spark-apps
       - /mnt/spark-data:/opt/spark-data

  namenode:
    image: platform-ds/hadoop-namenode:2.0.0-hadoop3.1.1-java8
    container_name: namenode
    build:
      context: ./namenode
      dockerfile: Dockerfile
      args:
        http_proxy:
        https_proxy:
        ftp_proxy:
    volumes:
      - "namenode:/hadoop/dfs/name"
    environment:
      - CLUSTER_NAME=test
    env_file:
      - .env    
    ports:
      - 9870:9870
      - 9000:9000  
      - 50070:50070

  datanode-1:
    image: platform-ds/hadoop-datanode:2.0.0-hadoop3.1.1-java8
    build:
      context: ./datanode
      dockerfile: Dockerfile
      args:
        http_proxy:
        https_proxy:
        ftp_proxy:
    container_name: datanode-1
    depends_on:
      - namenode
    volumes:
      - "datanode-1:/hadoop/dfs/data"
    env_file:
      - .env    
    ports:
      - 9871:9864
      - 50071:50075

  datanode-2:
    image: platform-ds/hadoop-datanode:2.0.0-hadoop3.1.1-java8
    build:
      context: ./datanode
      dockerfile: Dockerfile
      args:
        http_proxy:
        https_proxy:
        ftp_proxy:
    container_name: datanode-2
    depends_on:
      - namenode
    volumes:
      - "datanode-2:/hadoop/dfs/data"
    env_file:
      - .env    
    ports:
      - 9872:9864
      - 50072:50075

volumes:
  datanode-1:
    external:
      name: datanode-1
  
  datanode-2:
    external:
      name: datanode-2

  namenode:
    external:
      name: namenode
  
networks:
  default:
    external:
      name: ${DOCKER_NETWORK_NAME}
